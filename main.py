# main.py
import os
import re
import json
import requests
import subprocess
import sys
import tempfile
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from recipe_scrapers import scrape_me
import yt_dlp
from openai import OpenAI

# DO NOT auto-update yt-dlp - newer versions break with Python 3.11
# Pinned to 2024.10.22 which is stable

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ONLY CHANGE: spaces replaced with real TABs (yt-dlp requires this)
INSTAGRAM_COOKIES = """# Netscape HTTP Cookie File
# This file is generated by yt-dlp. Do not edit.
.instagram.com	TRUE	/	FALSE	1733875200	csrftoken	abxvXW3Nl1NZES5GKhSebmYt7chBhJcK
.instagram.com	TRUE	/	FALSE	1729999569	datr	raTLaBySXpCKW2Tm0ctSbzzO
.instagram.com	TRUE	/	FALSE	1731282769	ds_user_id	46425022
.instagram.com	TRUE	/	FALSE	1728789640	ig_did	8A6D83CE-01C7-4F7B-932A-4E1B53BDD872
.instagram.com	TRUE	/	FALSE	1728789631	ig_nrcb	1
.instagram.com	TRUE	/	FALSE	1730074964	mid	aM2o1AAEAAGpGRetOSmne116jpAx
.instagram.com	TRUE	/	FALSE	1765735567	rur	NHA\\05446425022\\0541794209167:01fe194320b30b02ad5593ee86a36c94aae2ba277c6de7d9928af768fdc52be1ce304e6d
.instagram.com	TRUE	/	FALSE	0	sessionid	46425022%3AgxJ1gyMKJIYHuM%3A1%3AAYiTBmGJRdKL3lJoh-62dkuF7a9-GkipKKFYEEa89w
.instagram.com	TRUE	/	FALSE	1731261982	wd	400x667
"""

class ExtractRequest(BaseModel):
    url: str

class YouTubeMetadataRequest(BaseModel):
    videoId: str

class DescriptionExtractionRequest(BaseModel):
    title: str
    description: str
    thumbnail: str = ""
    channelTitle: str = ""

def parse_with_ai(text: str):
    if not text.strip():
        return [], [], ""
    prompt = f"Extract recipe JSON {{ingredients: [], instructions: [], notes: \"\"}} from the following text (max 14000 chars):\n\n{text[:14000]}"
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            max_tokens=800
        )
        match = re.search(r"\{.*\}", resp.choices[0].message.content, re.DOTALL)
        if match:
            data = json.loads(match.group())
            return (
                data.get("ingredients", []),
                data.get("instructions", []),
                data.get("notes", "")
            )
    except:
        pass
    return [], [], ""

@app.post("/extract")
async def extract_recipe(request: ExtractRequest):
    url = request.url.strip()
    print(f"Processing: {url}")
    # 1. Regular recipe websites
    try:
        scraper = scrape_me(url)
        data = scraper.to_json()
        return {
            "title": data.get("title") or "Untitled Recipe",
            "ingredients": data.get("ingredients", []),
            "instructions": data.get("instructions", "").split("\n") if data.get("instructions") else [],
            "thumbnail": data.get("image", ""),
            "notes": "scraped with recipe-scrapers"
        }
    except:
        pass

    # 2. Video platforms (Instagram, TikTok, YouTube)
    ydl_opts = {
        "quiet": True,
        "no_warnings": True,
        "geo_bypass": True,
        "http_headers": {
            "User-Agent": "Instagram 219.0.0.12.117 Android",
            "x-ig-app-id": "936619743392459"
        },
    }
    cookie_file = None
    if INSTAGRAM_COOKIES:
        tmp = tempfile.NamedTemporaryFile(mode="w", delete=False, suffix=".txt")
        tmp.write(INSTAGRAM_COOKIES)
        tmp.close()
        cookie_file = tmp.name
        ydl_opts["cookiefile"] = cookie_file

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)
            thumbnail = info.get("thumbnail", "")
            text = f"{info.get('description', '')}\n{info.get('title', '')}"
            ingredients, instructions, notes = parse_with_ai(text)
            return {
                "title": info.get("title", "Video Recipe"),
                "ingredients": ingredients,
                "instructions": instructions,
                "thumbnail": thumbnail,
                "notes": notes or "extracted from video"
            }
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Video failed: {str(e)}")
    finally:
        if cookie_file and os.path.exists(cookie_file):
            os.unlink(cookie_file)

@app.post("/youtube-metadata")
async def youtube_metadata(request: YouTubeMetadataRequest):
    """Fetch YouTube video metadata using YouTube Data API"""
    video_id = request.videoId
    api_key = os.getenv("YOUTUBE_API_KEY")

    if not api_key:
        raise HTTPException(status_code=500, detail="YouTube API key not configured")

    print(f"Fetching YouTube metadata for: {video_id}")

    try:
        url = f"https://www.googleapis.com/youtube/v3/videos?part=snippet&id={video_id}&key={api_key}"
        response = requests.get(url)

        if response.status_code != 200:
            raise HTTPException(status_code=response.status_code, detail=f"YouTube API error: {response.text}")

        data = response.json()

        if not data.get("items") or len(data["items"]) == 0:
            raise HTTPException(status_code=404, detail="Video not found")

        video = data["items"][0]
        snippet = video["snippet"]

        result = {
            "title": snippet.get("title", ""),
            "description": snippet.get("description", ""),
            "thumbnail": snippet.get("thumbnails", {}).get("high", {}).get("url", "") or
                        snippet.get("thumbnails", {}).get("default", {}).get("url", ""),
            "channelTitle": snippet.get("channelTitle", "")
        }

        print(f"YouTube metadata retrieved: {result['title']}")
        return result

    except HTTPException:
        raise
    except Exception as e:
        print(f"Error fetching YouTube metadata: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to fetch YouTube metadata: {str(e)}")

@app.post("/extract-from-description")
async def extract_from_description(request: DescriptionExtractionRequest):
    """Extract recipe from YouTube video description using GPT-4o-mini"""

    if not request.description:
        raise HTTPException(status_code=400, detail="Description is required")

    if not os.getenv("OPENAI_API_KEY"):
        raise HTTPException(status_code=500, detail="OpenAI API key not configured")

    print("Extracting recipe from description...")

    prompt = f"""Extract a structured recipe from this YouTube video description.

Video Title: {request.title or 'Unknown'}
Channel: {request.channelTitle or 'Unknown'}

Description:
{request.description}

EXTRACTION RULES:
1. Extract ALL ingredients with their measurements exactly as written
2. Extract ALL cooking instructions in order
3. Extract prep time, cook time, and servings if mentioned
4. If times aren't specified, estimate based on recipe complexity
5. Identify cuisine type and difficulty level
6. Extract any dietary tags (vegetarian, vegan, gluten-free, etc.)

RESPONSE FORMAT:
Respond with ONLY a valid JSON object (no markdown, no code blocks):
{{
  "title": "recipe title from description or video title",
  "description": "brief description of the dish",
  "prepTime": number (minutes),
  "cookTime": number (minutes),
  "servings": number,
  "difficulty": "Easy" or "Medium" or "Hard",
  "cuisineType": "type of cuisine",
  "ingredients": [
    {{"name": "ingredient name", "quantity": "amount", "unit": "unit"}}
  ],
  "instructions": ["step 1", "step 2", ...],
  "dietaryTags": ["tag1", "tag2", ...],
  "notes": "any additional notes"
}}"""

    try:
        response = client.chat.completions.create(
            model='gpt-4o-mini',
            messages=[
                {"role": "system", "content": "You are a recipe extraction expert. Extract recipes from text descriptions accurately."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.3,
        )

        recipe_data = json.loads(response.choices[0].message.content)

        print(f"Description extraction successful: {recipe_data.get('title', 'Unknown')}")

        # Format ingredients as strings
        ingredients = []
        for ing in recipe_data.get("ingredients", []):
            if isinstance(ing, str):
                ingredients.append(ing)
            else:
                parts = []
                if ing.get("quantity"):
                    parts.append(str(ing["quantity"]))
                if ing.get("unit"):
                    parts.append(ing["unit"])
                if ing.get("name"):
                    parts.append(ing["name"])
                ingredients.append(" ".join(parts).strip())

        result = {
            "title": recipe_data.get("title") or request.title,
            "description": recipe_data.get("description", ""),
            "creator": request.channelTitle or "YouTube",
            "ingredients": ingredients,
            "instructions": recipe_data.get("instructions", []),
            "prep_time": recipe_data.get("prepTime", 15),
            "cook_time": recipe_data.get("cookTime", 30),
            "servings": str(recipe_data.get("servings", 4)),
            "yield": str(recipe_data.get("servings", 4)),
            "difficulty": recipe_data.get("difficulty", "Medium"),
            "cuisineType": recipe_data.get("cuisineType", "Global"),
            "dietaryTags": recipe_data.get("dietaryTags", []),
            "thumbnail": request.thumbnail or "",
            "image": request.thumbnail or "",
            "imageUrl": request.thumbnail or "",
            "notes": recipe_data.get("notes", "Extracted from video description"),
            "extractionMethod": "description"
        }

        return result

    except Exception as e:
        print(f"Error extracting from description: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to extract recipe from description: {str(e)}")

@app.get("/")
async def root():
    return {"status": "ok", "version": "2025-11-29"}