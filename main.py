# main.py
import os
import re
import json
import requests
import subprocess
import sys
import tempfile
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from recipe_scrapers import scrape_me
import yt_dlp
from openai import OpenAI

# Auto-update yt-dlp on every cold start (prevents Instagram breakage)
try:
    subprocess.check_call([
        sys.executable, "-m", "pip", "install", "--upgrade", "--no-cache-dir", "yt-dlp"
    ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
except:
    pass

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Working Instagram cookies â€“ valid November 2025
INSTAGRAM_COOKIES = """# Netscape HTTP Cookie File
# This file is generated by yt-dlp. Do not edit.

.instagram.com	TRUE	/	FALSE	1733875200	csrftoken	abxvXW3Nl1NZES5GKhSebmYt7chBhJcK
.instagram.com	TRUE	/	FALSE	1729999569	datr	raTLaBySXpCKW2Tm0ctSbzzO
.instagram.com	TRUE	/	FALSE	1731282769	ds_user_id	46425022
.instagram.com	TRUE	/	FALSE	1728789640	ig_did	8A6D83CE-01C7-4F7B-932A-4E1B53BDD872
.instagram.com	TRUE	/	FALSE	1728789631	ig_nrcb	1
.instagram.com	TRUE	/	FALSE	1730074964	mid	aM2o1AAEAAGpGRetOSmne116jpAx
.instagram.com	TRUE	/	FALSE	1765735567	rur	NHA\\05446425022\\0541794209167:01fe194320b30b02ad5593ee86a36c94aae2ba277c6de7d9928af768fdc52be1ce304e6d
.instagram.com	TRUE	/	FALSE	0	sessionid	46425022%3AgxJ1gyMKJIYHuM%3A1%3AAYiTBmGJRdKL3lJoh-62dkuF7a9-GkipKKFYEEa89w
.instagram.com	TRUE	/	FALSE	1731261982	wd	400x667
"""

class ExtractRequest(BaseModel):
    url: str

def parse_with_ai(text: str):
    if not text.strip():
        return [], [], ""
    prompt = f"Extract recipe JSON {{ingredients: [], instructions: [], notes: \"\"}} from the following text (max 14000 chars):\n\n{text[:14000]}"
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
            max_tokens=800
        )
        match = re.search(r"\{.*\}", resp.choices[0].message.content, re.DOTALL)
        if match:
            data = json.loads(match.group())
            return (
                data.get("ingredients", []),
                data.get("instructions", []),
                data.get("notes", "")
            )
    except:
        pass
    return [], [], ""

@app.post("/extract")
async def extract_recipe(request: ExtractRequest):
    url = request.url.strip()
    print(f"Processing: {url}")

    # 1. Regular recipe websites
    try:
        scraper = scrape_me(url)
        data = scraper.to_json()
        return {
            "title": data.get("title") or "Untitled Recipe",
            "ingredients": data.get("ingredients", []),
            "instructions": data.get("instructions", "").split("\n") if data.get("instructions") else [],
            "thumbnail": data.get("image", ""),
            "notes": "scraped with recipe-scrapers"
        }
    except:
        pass

    # 2. Video platforms (Instagram, TikTok, YouTube)
    ydl_opts = {
        "quiet": True,
        "no_warnings": True,
        "geo_bypass": True,
        "http_headers": {
            "User-Agent": "Instagram 219.0.0.12.117 Android",
            "x-ig-app-id": "936619743392459"
        },
    }

    cookie_file = None
    if INSTAGRAM_COOKIES:
        tmp = tempfile.NamedTemporaryFile(mode="w", delete=False, suffix=".txt")
        tmp.write(INSTAGRAM_COOKIES)
        tmp.close()
        cookie_file = tmp.name
        ydl_opts["cookiefile"] = cookie_file

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)
            thumbnail = info.get("thumbnail", "")
            text = f"{info.get('description', '')}\n{info.get('title', '')}"
            ingredients, instructions, notes = parse_with_ai(text)

            return {
                "title": info.get("title", "Video Recipe"),
                "ingredients": ingredients,
                "instructions": instructions,
                "thumbnail": thumbnail,
                "notes": notes or "extracted from video"
            }
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Video failed: {str(e)}")
    finally:
        if cookie_file and os.path.exists(cookie_file):
            os.unlink(cookie_file)

@app.get("/")
async def root():
    return {"status": "ok", "version": "2025-11-19"}